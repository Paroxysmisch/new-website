{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"About me I am a fourth year computer science student interested in applying Geometric Deep Learning (mostly Graph Neural Networks) and Neural Algorithmic Reasoning to real-world problems. My interests include accelerating Computational Genomics, Computer Architecture, Natural Language Processing, and Graphics with machine learning. I am currently working on the use of GNNs and NAR for accelerating de novo genome assembly. Academic interests Geometric Deep Learning (GDL) is a framework leveraging the geometry in data, through groups, representations, and principles of invariance and equivariance, to learn more effective machine learning models. Central to GDL are symmetries\u2014transformations that leave an object unchanged. In the context of machine learning, relevant symmetries can arise in various forms: symmetries of the input data (e.g. rotational symmetries in molecular structure); the label function mapping the input to some output (e.g. the image classification function is invariant to the location of the object in the image), the domain our data lives on (e.g. data living on a set is invariant to the permutation of items in the set), or even symmetries in the model's parameterization. Through encoding symmetry within our model architecture, we restrict the space of functions that can be represented to those that respect these symmetries. This makes models more performant, improves generalization, and can make learning more sample/data efficient. I am interested in utilizing the GDL framework to improve model architectures for existing tasks, as well as designing new approaches for tackling emerging problem domains. Natural Language Processing (NLP) has been a key interest of mine, where my focus lies in the study and improvement of the Transformer architecture. I have worked on improving the positional embeddings, alternative attention mechanisms, and exploring use with other architectures such as the Mamba Selective State Space model, for instance. Additionally, I have looked exploring these architectures from a theoretical standpoint using the tools provided by GDL to draw novel insights. Reinforcement Learning (RL) is a paradigm for learning optimal behavior through interaction with an environment. My interest in RL stems from its potential to aid with scientific discovery, experimenting with novel model architectures such as the Mamba Selective State Space model, and Graph Neural Networks. Computer Architecture My interest in computer architecture lies in the interface between machine learning models and the hardware they run on, as well as improving and designing new architectures for machine learning workloads.","title":"Yash Shah"},{"location":"#about-me","text":"I am a fourth year computer science student interested in applying Geometric Deep Learning (mostly Graph Neural Networks) and Neural Algorithmic Reasoning to real-world problems. My interests include accelerating Computational Genomics, Computer Architecture, Natural Language Processing, and Graphics with machine learning. I am currently working on the use of GNNs and NAR for accelerating de novo genome assembly.","title":"About me"},{"location":"#academic-interests","text":"Geometric Deep Learning (GDL) is a framework leveraging the geometry in data, through groups, representations, and principles of invariance and equivariance, to learn more effective machine learning models. Central to GDL are symmetries\u2014transformations that leave an object unchanged. In the context of machine learning, relevant symmetries can arise in various forms: symmetries of the input data (e.g. rotational symmetries in molecular structure); the label function mapping the input to some output (e.g. the image classification function is invariant to the location of the object in the image), the domain our data lives on (e.g. data living on a set is invariant to the permutation of items in the set), or even symmetries in the model's parameterization. Through encoding symmetry within our model architecture, we restrict the space of functions that can be represented to those that respect these symmetries. This makes models more performant, improves generalization, and can make learning more sample/data efficient. I am interested in utilizing the GDL framework to improve model architectures for existing tasks, as well as designing new approaches for tackling emerging problem domains. Natural Language Processing (NLP) has been a key interest of mine, where my focus lies in the study and improvement of the Transformer architecture. I have worked on improving the positional embeddings, alternative attention mechanisms, and exploring use with other architectures such as the Mamba Selective State Space model, for instance. Additionally, I have looked exploring these architectures from a theoretical standpoint using the tools provided by GDL to draw novel insights. Reinforcement Learning (RL) is a paradigm for learning optimal behavior through interaction with an environment. My interest in RL stems from its potential to aid with scientific discovery, experimenting with novel model architectures such as the Mamba Selective State Space model, and Graph Neural Networks. Computer Architecture My interest in computer architecture lies in the interface between machine learning models and the hardware they run on, as well as improving and designing new architectures for machine learning workloads.","title":"Academic interests"},{"location":"education/","text":"University of Cambridge MEng Computer Science Distinction (2024\u20132025) Modules: ML & Physical World, Computer Architecture, Natural Language Syntax & Parsing, Geometric Deep Learning, and Reinforcement Learning BA Computer Science 1st Class (2020\u20132023)","title":"Education"},{"location":"education/#university-of-cambridge","text":"","title":"University of Cambridge"},{"location":"education/#meng-computer-science","text":"Distinction (2024\u20132025) Modules: ML & Physical World, Computer Architecture, Natural Language Syntax & Parsing, Geometric Deep Learning, and Reinforcement Learning","title":"MEng Computer Science"},{"location":"education/#ba-computer-science","text":"1st Class (2020\u20132023)","title":"BA Computer Science"},{"location":"projects/","text":"Dissertations Graph Neural Networks for Accelerated Genome Assembly My postgraduate dissertation project using techniques from Geometric Deep Learning to resolve the true genome sequence in genome assembly graphs built from erroneous reads. genome-assembly Physically based CUDA-Accelerated Path Tracer My undergraduate dissertation project utilizing the Cook-Torrance Microfacet Model, acceleration data structures, several BRDF importance sampling techniques, and deep learning denoising to achieve photo-realistic rendering on NVIDIA GPUs. path-tracer Other projects Reinforcement Learning for Hydrophobic-Polar Protein Folding Achieved state of the art results using Double Deep Q-Networks, Mamba Selective State Space Models, and Graph Attention Networks on the HP model for protein folding. hp-model Natural Language Parser Comparison Evaluated and compared the performance of two natural language constituency parsers from quantitative and linguistic standpoints. parser-comparision-report.pdf Computer Architecture Essays A collection containing my writings from computer architecture papers discussing trends, state-of-the-art microprocessor & memory design, hardware reliability, specification, verification & test, security, and hardware accelerators for machine learning. computer-architecture-essays Optimizing a spark-ignition engine Built a thermodynamically accurate engine simulation. Gaussian Processes and Bayesian Optimization was then used to optimize the engine design to maximize thermodynamic efficiency. L48_final_report.pdf SLR(1) parsing table generator Simple Left-to-Right Rightmost-derivation 1-symbol look-ahead parsing table generator for deterministic context-free languages. ParserJava","title":"Projects"},{"location":"projects/#dissertations","text":"","title":"Dissertations"},{"location":"projects/#graph-neural-networks-for-accelerated-genome-assembly","text":"My postgraduate dissertation project using techniques from Geometric Deep Learning to resolve the true genome sequence in genome assembly graphs built from erroneous reads. genome-assembly","title":"Graph Neural Networks for Accelerated Genome Assembly"},{"location":"projects/#physically-based-cuda-accelerated-path-tracer","text":"My undergraduate dissertation project utilizing the Cook-Torrance Microfacet Model, acceleration data structures, several BRDF importance sampling techniques, and deep learning denoising to achieve photo-realistic rendering on NVIDIA GPUs. path-tracer","title":"Physically based CUDA-Accelerated Path Tracer"},{"location":"projects/#other-projects","text":"","title":"Other projects"},{"location":"projects/#reinforcement-learning-for-hydrophobic-polar-protein-folding","text":"Achieved state of the art results using Double Deep Q-Networks, Mamba Selective State Space Models, and Graph Attention Networks on the HP model for protein folding. hp-model","title":"Reinforcement Learning for Hydrophobic-Polar Protein Folding"},{"location":"projects/#natural-language-parser-comparison","text":"Evaluated and compared the performance of two natural language constituency parsers from quantitative and linguistic standpoints. parser-comparision-report.pdf","title":"Natural Language Parser Comparison"},{"location":"projects/#computer-architecture-essays","text":"A collection containing my writings from computer architecture papers discussing trends, state-of-the-art microprocessor & memory design, hardware reliability, specification, verification & test, security, and hardware accelerators for machine learning. computer-architecture-essays","title":"Computer Architecture Essays"},{"location":"projects/#optimizing-a-spark-ignition-engine","text":"Built a thermodynamically accurate engine simulation. Gaussian Processes and Bayesian Optimization was then used to optimize the engine design to maximize thermodynamic efficiency. L48_final_report.pdf","title":"Optimizing a spark-ignition engine"},{"location":"projects/#slr1-parsing-table-generator","text":"Simple Left-to-Right Rightmost-derivation 1-symbol look-ahead parsing table generator for deterministic context-free languages. ParserJava","title":"SLR(1) parsing table generator"},{"location":"work/","text":"This is a test page.","title":"Work"},{"location":"blog/article0/","text":"This is a test blog Titles must start with ##","title":"Your document title"},{"location":"blog/article0/#titles-must-start-with","text":"","title":"Titles must start with ##"}]}